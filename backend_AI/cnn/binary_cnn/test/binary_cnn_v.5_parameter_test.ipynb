{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(start, end, step):\n",
    "    lst = []\n",
    "    round_list = []\n",
    "    st = start\n",
    "    \n",
    "    while st < end:\n",
    "        lst.append(st)\n",
    "        st += step\n",
    "    for i in lst:\n",
    "        round_list.append(round(i, 2))\n",
    "    return round_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n"
     ]
    }
   ],
   "source": [
    "lst = get_list(0, 0.4, 0.05)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 15, 20, 25, 30, 35, 40, 45]\n"
     ]
    }
   ],
   "source": [
    "lst= get_list(10, 50, 5)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "\n",
    "\"\"\"이미지 증강 함수\"\"\"\n",
    "\n",
    "def image_augmentation(files, index, limit, image_width, image_height):\n",
    "    random_files = []\n",
    "    X_array =[]\n",
    "    y_array = []\n",
    "    images = []\n",
    "    data = []\n",
    "    \n",
    "#     print('파일 리스트')\n",
    "#     print(files)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            random_files.append(random.choice(files))\n",
    "            file = random_files[-1]\n",
    "            print('선택된 파일')\n",
    "            print(file)\n",
    "\n",
    "            img_bgr = cv2.imread(file , cv2.IMREAD_COLOR)\n",
    "            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img_rgb, (image_width, image_height))\n",
    "            \n",
    "#             img90 =  cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)  # 시계 방향으로 90도 회전\n",
    "#             img180 =  cv2.rotate(img, cv2.ROTATE_180)  # 180도 회전\n",
    "#             img270 =  cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE) # 반시계 방향 90도 회전\n",
    "\n",
    "            images.append(img)\n",
    "            images.append(cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE))  # 시계 방향으로 90도 회전\n",
    "            images.append(cv2.rotate(img, cv2.ROTATE_180))  # 180도 회전\n",
    "            images.append(cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)) # 반시계 방향 90도 회전\n",
    "            \n",
    "            for image in images:\n",
    "                data = np.asarray(image)\n",
    "                X_array.append(data)\n",
    "                y_array.append(index)\n",
    "        \n",
    "            if len(X_array) >= limit:\n",
    "                break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(str(i)+\" 번째에서 에러 \")\n",
    "            #             remove(f)\n",
    "        pass \n",
    "    \n",
    "\n",
    "    \n",
    "    return X_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\"\"\"이미지 뽑기 함수\"\"\"\n",
    "\n",
    "def image_selector(files, index, limit, image_width, image_height):\n",
    "    random_files = []\n",
    "    X_array = []\n",
    "    y_array = []\n",
    "    data = []\n",
    "    \n",
    "    for i in range(limit):\n",
    "        random_files.append(random.choice(files))\n",
    "#     print(random_files)\n",
    "    \n",
    "    for i, f in enumerate(random_files):\n",
    "        try:\n",
    "            img_bgr = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "            image_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(image_rgb, (image_width, image_height))\n",
    "\n",
    "            data = np.asarray(img)\n",
    "            #Y는 0 아니면 1이니까 index값으로 넣는다.\n",
    "\n",
    "            X_array.append(data)\n",
    "            y_array.append(index)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(str(i)+\" 번째에서 에러 \")\n",
    "    #             remove(f)\n",
    "            pass \n",
    "            \n",
    "    return X_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "\"\"\"하위 폴더 및 파일 탐색\"\"\"\n",
    "    \n",
    "def is_dir_file(dir_path, dir_list, img_limit, img_limit_list):\n",
    "    \n",
    "    folders = os.listdir(dir_path)\n",
    "    \n",
    "    for folder in folders:\n",
    "        path_detail = os.path.join(dir_path, folder)\n",
    "        \n",
    "        if os.path.isdir(path_detail):\n",
    "            new_img_limit = int(img_limit / len(folders))\n",
    "            \n",
    "            is_dir_file(path_detail, dir_list, new_img_limit, img_limit_list)\n",
    "        else:    \n",
    "            print(dir_path + ' img limit : ' + str(img_limit))\n",
    "            dir_list.append(dir_path)\n",
    "            img_limit_list.append(img_limit)\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ad', 'non_ad']\n",
      "./binary_cnn/train\\ad\\bill\\classification\\1 img limit : 72\n",
      "./binary_cnn/train\\ad\\bill\\non_classification img limit : 72\n",
      "./binary_cnn/train\\ad\\coin\\1 img limit : 145\n",
      "./binary_cnn/train\\ad\\general_product\\classification\\1 img limit : 72\n",
      "./binary_cnn/train\\ad\\general_product\\non_classification img limit : 72\n",
      "./binary_cnn/train\\ad\\graph\\classification\\1 img limit : 72\n",
      "./binary_cnn/train\\ad\\graph\\non_classification img limit : 72\n",
      "./binary_cnn/train\\ad\\human\\1 img limit : 29\n",
      "./binary_cnn/train\\ad\\human\\2 img limit : 29\n",
      "./binary_cnn/train\\ad\\human\\3 img limit : 29\n",
      "./binary_cnn/train\\ad\\human\\4 img limit : 29\n",
      "./binary_cnn/train\\ad\\human\\ambiguous_data img limit : 29\n",
      "./binary_cnn/train\\ad\\lotto_N\\1 img limit : 145\n",
      "./binary_cnn/train\\ad\\lotto_P\\1 img limit : 145\n",
      "./binary_cnn/train\\ad\\microbe\\1 img limit : 145\n",
      "./binary_cnn/train\\ad\\part_of_human\\1 img limit : 29\n",
      "./binary_cnn/train\\ad\\part_of_human\\2 img limit : 29\n",
      "./binary_cnn/train\\ad\\part_of_human\\3 img limit : 29\n",
      "./binary_cnn/train\\ad\\part_of_human\\4 img limit : 29\n",
      "./binary_cnn/train\\ad\\part_of_human\\ambiguous_data img limit : 29\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\1 img limit : 18\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\2 img limit : 18\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\3 img limit : 18\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\4 img limit : 18\n",
      "./binary_cnn/train\\ad\\photoshop\\non_classification img limit : 72\n",
      "./binary_cnn/train\\ad\\picture\\classification\\1 img limit : 18\n",
      "./binary_cnn/train\\ad\\picture\\classification\\2 img limit : 18\n",
      "./binary_cnn/train\\ad\\picture\\classification\\3 img limit : 18\n",
      "./binary_cnn/train\\ad\\picture\\classification\\4 img limit : 18\n",
      "./binary_cnn/train\\ad\\picture\\non_classification img limit : 72\n",
      "./binary_cnn/train\\non_ad\\1 img limit : 1600\n",
      "[[0, './binary_cnn/train\\\\ad\\\\bill\\\\classification\\\\1'], [0, './binary_cnn/train\\\\ad\\\\bill\\\\non_classification'], [0, './binary_cnn/train\\\\ad\\\\coin\\\\1'], [0, './binary_cnn/train\\\\ad\\\\general_product\\\\classification\\\\1'], [0, './binary_cnn/train\\\\ad\\\\general_product\\\\non_classification'], [0, './binary_cnn/train\\\\ad\\\\graph\\\\classification\\\\1'], [0, './binary_cnn/train\\\\ad\\\\graph\\\\non_classification'], [0, './binary_cnn/train\\\\ad\\\\human\\\\1'], [0, './binary_cnn/train\\\\ad\\\\human\\\\2'], [0, './binary_cnn/train\\\\ad\\\\human\\\\3'], [0, './binary_cnn/train\\\\ad\\\\human\\\\4'], [0, './binary_cnn/train\\\\ad\\\\human\\\\ambiguous_data'], [0, './binary_cnn/train\\\\ad\\\\lotto_N\\\\1'], [0, './binary_cnn/train\\\\ad\\\\lotto_P\\\\1'], [0, './binary_cnn/train\\\\ad\\\\microbe\\\\1'], [0, './binary_cnn/train\\\\ad\\\\part_of_human\\\\1'], [0, './binary_cnn/train\\\\ad\\\\part_of_human\\\\2'], [0, './binary_cnn/train\\\\ad\\\\part_of_human\\\\3'], [0, './binary_cnn/train\\\\ad\\\\part_of_human\\\\4'], [0, './binary_cnn/train\\\\ad\\\\part_of_human\\\\ambiguous_data'], [0, './binary_cnn/train\\\\ad\\\\photoshop\\\\classification\\\\1'], [0, './binary_cnn/train\\\\ad\\\\photoshop\\\\classification\\\\2'], [0, './binary_cnn/train\\\\ad\\\\photoshop\\\\classification\\\\3'], [0, './binary_cnn/train\\\\ad\\\\photoshop\\\\classification\\\\4'], [0, './binary_cnn/train\\\\ad\\\\photoshop\\\\non_classification'], [0, './binary_cnn/train\\\\ad\\\\picture\\\\classification\\\\1'], [0, './binary_cnn/train\\\\ad\\\\picture\\\\classification\\\\2'], [0, './binary_cnn/train\\\\ad\\\\picture\\\\classification\\\\3'], [0, './binary_cnn/train\\\\ad\\\\picture\\\\classification\\\\4'], [0, './binary_cnn/train\\\\ad\\\\picture\\\\non_classification'], [1, './binary_cnn/train\\\\non_ad\\\\1']]\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "./binary_cnn/train\\ad\\bill\\classification\\1\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\classification\\1\\9.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\classification\\1\\9.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\classification\\1\\8.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\classification\\1\\1.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\classification\\1\\28.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\classification\\1\\18.jpg\n",
      "./binary_cnn/train\\ad\\bill\\classification\\1파일 길이 : 84\n",
      "./binary_cnn/train\\ad\\bill\\non_classification\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\non_classification\\31.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\non_classification\\31.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\non_classification\\31.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\non_classification\\31.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\non_classification\\31.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\bill\\non_classification\\31.jpg\n",
      "./binary_cnn/train\\ad\\bill\\non_classification파일 길이 : 84\n",
      "./binary_cnn/train\\ad\\coin\\1\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\coin\\1\\10.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\coin\\1\\89.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\coin\\1\\82.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\coin\\1\\89.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\coin\\1\\53.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\coin\\1\\69.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\coin\\1\\17.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\coin\\1\\22.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\coin\\1\\17.jpg\n",
      "./binary_cnn/train\\ad\\coin\\1파일 길이 : 180\n",
      "./binary_cnn/train\\ad\\general_product\\classification\\1\n",
      "./binary_cnn/train\\ad\\general_product\\classification\\1파일 길이 : 72\n",
      "./binary_cnn/train\\ad\\general_product\\non_classification\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\general_product\\non_classification\\13.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\general_product\\non_classification\\23.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\general_product\\non_classification\\33.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\general_product\\non_classification\\21.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\general_product\\non_classification\\4.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\general_product\\non_classification\\21.jpg\n",
      "./binary_cnn/train\\ad\\general_product\\non_classification파일 길이 : 84\n",
      "./binary_cnn/train\\ad\\graph\\classification\\1\n",
      "./binary_cnn/train\\ad\\graph\\classification\\1파일 길이 : 72\n",
      "./binary_cnn/train\\ad\\graph\\non_classification\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\graph\\non_classification\\4.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\graph\\non_classification\\4.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\graph\\non_classification\\4.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\graph\\non_classification\\4.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\graph\\non_classification\\4.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\graph\\non_classification\\4.jpg\n",
      "./binary_cnn/train\\ad\\graph\\non_classification파일 길이 : 84\n",
      "./binary_cnn/train\\ad\\human\\1\n",
      "./binary_cnn/train\\ad\\human\\1파일 길이 : 29\n",
      "./binary_cnn/train\\ad\\human\\2\n",
      "./binary_cnn/train\\ad\\human\\2파일 길이 : 29\n",
      "./binary_cnn/train\\ad\\human\\3\n",
      "./binary_cnn/train\\ad\\human\\3파일 길이 : 29\n",
      "./binary_cnn/train\\ad\\human\\4\n",
      "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
      "\n",
      "20 번째에서 에러 \n",
      "./binary_cnn/train\\ad\\human\\4파일 길이 : 28\n",
      "./binary_cnn/train\\ad\\human\\ambiguous_data\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\human\\ambiguous_data\\76.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\human\\ambiguous_data\\11.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\human\\ambiguous_data\\77.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\human\\ambiguous_data\\11.jpg\n",
      "./binary_cnn/train\\ad\\human\\ambiguous_data파일 길이 : 40\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\\4.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\\23.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\\19.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\\7.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\\12.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\\23.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\\8.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\\27.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_N\\1\\6.jpg\n",
      "./binary_cnn/train\\ad\\lotto_N\\1파일 길이 : 180\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\\30.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\\20.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\\19.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\\17.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\\5.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\\10.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\\29.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\\8.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\lotto_P\\1\\19.jpg\n",
      "./binary_cnn/train\\ad\\lotto_P\\1파일 길이 : 180\n",
      "./binary_cnn/train\\ad\\microbe\\1\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\microbe\\1\\77.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\microbe\\1\\89.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\microbe\\1\\34.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\microbe\\1\\66.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\microbe\\1\\21.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\microbe\\1\\47.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\microbe\\1\\67.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\microbe\\1\\38.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\microbe\\1\\41.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./binary_cnn/train\\ad\\microbe\\1파일 길이 : 180\n",
      "./binary_cnn/train\\ad\\part_of_human\\1\n",
      "./binary_cnn/train\\ad\\part_of_human\\1파일 길이 : 29\n",
      "./binary_cnn/train\\ad\\part_of_human\\2\n",
      "./binary_cnn/train\\ad\\part_of_human\\2파일 길이 : 29\n",
      "./binary_cnn/train\\ad\\part_of_human\\3\n",
      "./binary_cnn/train\\ad\\part_of_human\\3파일 길이 : 29\n",
      "./binary_cnn/train\\ad\\part_of_human\\4\n",
      "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
      "\n",
      "1 번째에서 에러 \n",
      "./binary_cnn/train\\ad\\part_of_human\\4파일 길이 : 28\n",
      "./binary_cnn/train\\ad\\part_of_human\\ambiguous_data\n",
      "./binary_cnn/train\\ad\\part_of_human\\ambiguous_data파일 길이 : 29\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\1\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\1파일 길이 : 18\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\2\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\2파일 길이 : 18\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\3\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\3파일 길이 : 18\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\4\n",
      "./binary_cnn/train\\ad\\photoshop\\classification\\4파일 길이 : 18\n",
      "./binary_cnn/train\\ad\\photoshop\\non_classification\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\photoshop\\non_classification\\9.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\photoshop\\non_classification\\8.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\photoshop\\non_classification\\81.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\photoshop\\non_classification\\1.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\photoshop\\non_classification\\81.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\photoshop\\non_classification\\9.jpg\n",
      "./binary_cnn/train\\ad\\photoshop\\non_classification파일 길이 : 84\n",
      "./binary_cnn/train\\ad\\picture\\classification\\1\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\picture\\classification\\1\\5.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\picture\\classification\\1\\1.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\picture\\classification\\1\\6.jpg\n",
      "./binary_cnn/train\\ad\\picture\\classification\\1파일 길이 : 24\n",
      "./binary_cnn/train\\ad\\picture\\classification\\2\n",
      "./binary_cnn/train\\ad\\picture\\classification\\2파일 길이 : 18\n",
      "./binary_cnn/train\\ad\\picture\\classification\\3\n",
      "./binary_cnn/train\\ad\\picture\\classification\\3파일 길이 : 18\n",
      "./binary_cnn/train\\ad\\picture\\classification\\4\n",
      "./binary_cnn/train\\ad\\picture\\classification\\4파일 길이 : 18\n",
      "./binary_cnn/train\\ad\\picture\\non_classification\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\picture\\non_classification\\39.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\picture\\non_classification\\9.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\picture\\non_classification\\10.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\picture\\non_classification\\42.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\picture\\non_classification\\3.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\ad\\picture\\non_classification\\46.jpg\n",
      "./binary_cnn/train\\ad\\picture\\non_classification파일 길이 : 84\n",
      "./binary_cnn/train\\non_ad\\1\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\277.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\27.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\67.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\66.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\65.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\377.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\350.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\95.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\371.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\274.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\263.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\337.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\314.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\216.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\327.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\189.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\129.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\40.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\322.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\82.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\351.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\278.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\106.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\338.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\156.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\219.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\251.jpg\n",
      "선택된 파일\n",
      "./binary_cnn/train\\non_ad\\1\\360.jpg\n",
      "./binary_cnn/train\\non_ad\\1파일 길이 : 1624\n",
      "총 파일 길이 : 3441\n",
      "3441 3441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이미지 크기 인자를 조절하면서 적용'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#본 코드 시작\n",
    "\n",
    "# from PIL import Image\n",
    "# import glob, sys, numpy as np\n",
    "# from  keras.utils import np_utils\n",
    "\n",
    "import cv2\n",
    "import os, glob\n",
    "from os import remove\n",
    "import numpy as np\n",
    "\n",
    "img_dir = './binary_cnn/train'\n",
    "# categories = ['ad', 'non_ad']\n",
    "categories = os.listdir(img_dir)\n",
    "\n",
    "sum = 0\n",
    "ad_index = 0\n",
    "non_ad_index = 1\n",
    "image_width, image_height = 128, 128\n",
    "\n",
    "# file_directory = []\n",
    "file_list_index = []\n",
    "img_limit_list = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "np_classes = len(categories)    \n",
    "print(categories)\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    file_directory = []\n",
    "    img_dir_detail = os.path.join(img_dir, category)\n",
    "    \n",
    "    if i == ad_index:\n",
    "        img_limit = 1600\n",
    "    elif i == non_ad_index:\n",
    "        img_limit = 1600\n",
    "        \n",
    "    is_dir_file(img_dir_detail, file_directory, img_limit, img_limit_list)\n",
    "    \n",
    "    for directory in file_directory:\n",
    "        file_list_index.append([i, directory])\n",
    "#     file_list_index.append([i, file_directory])\n",
    "    \n",
    "# print(file_directory)\n",
    "print(file_list_index)\n",
    "\n",
    "for lst in file_list_index:\n",
    "#     print(lst)\n",
    "    print(lst[0])\n",
    "\n",
    "count = 0\n",
    "\n",
    "# for (index, directories) in file_list_index:\n",
    "for index, directory in file_list_index:\n",
    "#     for directory in directories:\n",
    "    print(directory)\n",
    "    files = glob.glob(directory + \"/*.jpg\")\n",
    "    len_file = len(files)\n",
    "\n",
    "#     if index == ad_index:\n",
    "#         img_limit = 20\n",
    "#     elif index == non_ad_index:\n",
    "#         img_limit = 100\n",
    "\n",
    "    img_limit = img_limit_list[count]\n",
    "\n",
    "    if len_file <img_limit:\n",
    "        X_temp, y_temp = image_augmentation(files, index, img_limit, image_width, image_height)\n",
    "    else:\n",
    "        X_temp, y_temp = image_selector(files, index, img_limit, image_width, image_height)\n",
    "\n",
    "#         X.__add__(X_temp)\n",
    "#         y.__add__(y_temp)\n",
    "\n",
    "    X = X + X_temp\n",
    "    y = y + y_temp\n",
    "\n",
    "    len_file = len(X_temp)\n",
    "    print(directory + '파일 길이 : ' + str(len_file))\n",
    "    sum += len_file\n",
    "    count += 1\n",
    "        \n",
    "    \n",
    "print('총 파일 길이 : ' + str(sum))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(y)\n",
    "\n",
    "print(len(X), len(Y))\n",
    "\n",
    "\"\"\"이미지 크기 인자를 조절하면서 적용\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2580, 128, 128, 3)\n",
      "2580\n",
      "(2580,)\n",
      "(861,)\n",
      "[1360 1220]\n",
      "[457 404]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with K.tf_ops.device('/device:GPU:0'):\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "#     model_dir = 'C:\\\\Users\\\\kimkm\\\\광고\\\\model'\n",
    "#     if not os.path.exists(model_dir):\n",
    "#         os.mkdir(model_dir)\n",
    "#     model_path = model_dir + \"\\\\ad_non_ad_classify.model\"\n",
    "    \n",
    "#     checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,125,441\n",
      "Trainable params: 1,124,673\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "41/41 [==============================] - 20s 498ms/step - loss: 0.5951 - accuracy: 0.7310\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 22s 530ms/step - loss: 0.2655 - accuracy: 0.8950\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 23s 558ms/step - loss: 0.1302 - accuracy: 0.9570\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 23s 558ms/step - loss: 0.0587 - accuracy: 0.9818\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 23s 559ms/step - loss: 0.0384 - accuracy: 0.9891\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 23s 572ms/step - loss: 0.0211 - accuracy: 0.9942\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 24s 588ms/step - loss: 0.0149 - accuracy: 0.9977\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 24s 588ms/step - loss: 0.0124 - accuracy: 0.9965\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 24s 597ms/step - loss: 0.0170 - accuracy: 0.9961\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 23s 568ms/step - loss: 0.0095 - accuracy: 0.9988\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 24s 579ms/step - loss: 0.0062 - accuracy: 0.9992\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 24s 593ms/step - loss: 0.0063 - accuracy: 0.9992\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 24s 585ms/step - loss: 0.0088 - accuracy: 0.9984\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 24s 595ms/step - loss: 0.0149 - accuracy: 0.9961\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 25s 604ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 23s 572ms/step - loss: 0.0040 - accuracy: 0.9996\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 24s 582ms/step - loss: 0.0040 - accuracy: 0.9996\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - 24s 581ms/step - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - 25s 603ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - 23s 572ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "27/27 [==============================] - 2s 68ms/step - loss: 0.0215 - accuracy: 0.9919\n",
      "Epoch 1/20\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.1873e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "39/39 [==============================] - 23s 588ms/step - loss: 7.4389e-04 - accuracy: 1.0000 - val_loss: 2.7368e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "39/39 [==============================] - 24s 623ms/step - loss: 6.1762e-04 - accuracy: 1.0000 - val_loss: 2.7321e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "39/39 [==============================] - 25s 641ms/step - loss: 7.3039e-04 - accuracy: 1.0000 - val_loss: 3.4395e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "39/39 [==============================] - 24s 614ms/step - loss: 4.6534e-04 - accuracy: 1.0000 - val_loss: 1.5277e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 5.5477e-04 - accuracy: 1.0000 - val_loss: 1.6976e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 3.5783e-04 - accuracy: 1.0000 - val_loss: 1.6205e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 3.5534e-04 - accuracy: 1.0000 - val_loss: 4.2528e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 3.4656e-04 - accuracy: 1.0000 - val_loss: 1.2046e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 2.9506e-04 - accuracy: 1.0000 - val_loss: 1.3060e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 4.5256e-04 - accuracy: 1.0000 - val_loss: 9.2715e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "39/39 [==============================] - 23s 601ms/step - loss: 2.2843e-04 - accuracy: 1.0000 - val_loss: 8.0081e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 2.2162e-04 - accuracy: 1.0000 - val_loss: 6.2481e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "39/39 [==============================] - 23s 587ms/step - loss: 1.8482e-04 - accuracy: 1.0000 - val_loss: 7.0735e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "39/39 [==============================] - 23s 588ms/step - loss: 5.9266e-04 - accuracy: 1.0000 - val_loss: 1.2525e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "39/39 [==============================] - 23s 577ms/step - loss: 6.8856e-04 - accuracy: 1.0000 - val_loss: 2.5821e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 4.1670e-04 - accuracy: 1.0000 - val_loss: 1.1098e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 4.2630e-04 - accuracy: 1.0000 - val_loss: 5.1836e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "39/39 [==============================] - 22s 566ms/step - loss: 2.7982e-04 - accuracy: 1.0000 - val_loss: 1.3533e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "39/39 [==============================] - 23s 588ms/step - loss: 3.1346e-04 - accuracy: 1.0000 - val_loss: 2.4985e-04 - val_accuracy: 1.0000\n",
      "27/27 [==============================] - 2s 72ms/step - loss: 0.0405 - accuracy: 0.9872\n",
      "Epoch 1/20\n",
      "37/37 [==============================] - 22s 586ms/step - loss: 2.1531e-04 - accuracy: 1.0000 - val_loss: 5.0027e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - 21s 576ms/step - loss: 2.2772e-04 - accuracy: 1.0000 - val_loss: 6.5238e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - 22s 590ms/step - loss: 1.6764e-04 - accuracy: 1.0000 - val_loss: 5.8005e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - 21s 571ms/step - loss: 2.9690e-04 - accuracy: 1.0000 - val_loss: 8.5963e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - 21s 574ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - 21s 572ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 2.4533 - val_accuracy: 0.7364\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - 21s 574ms/step - loss: 0.0227 - accuracy: 0.9910 - val_loss: 7.2157 - val_accuracy: 0.6124\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - 22s 596ms/step - loss: 0.0877 - accuracy: 0.9664 - val_loss: 4.4233 - val_accuracy: 0.6550\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - 22s 595ms/step - loss: 0.0318 - accuracy: 0.9897 - val_loss: 0.2613 - val_accuracy: 0.9341\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - 22s 583ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0352 - val_accuracy: 0.9845\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - 23s 611ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - 22s 590ms/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.0169 - val_accuracy: 0.9961\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - 22s 602ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9961\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - 22s 604ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9961\n",
      "Epoch 15/20\n",
      "37/37 [==============================] - 22s 594ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9922\n",
      "Epoch 16/20\n",
      "37/37 [==============================] - 22s 604ms/step - loss: 9.7232e-04 - accuracy: 0.9996 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "37/37 [==============================] - 22s 600ms/step - loss: 6.4065e-04 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 18/20\n",
      "37/37 [==============================] - 22s 597ms/step - loss: 9.1864e-04 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 19/20\n",
      "37/37 [==============================] - 22s 586ms/step - loss: 4.7635e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9961\n",
      "Epoch 20/20\n",
      "37/37 [==============================] - 818s 22s/step - loss: 0.0013 - accuracy: 0.9991 - val_loss: 0.0133 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 89ms/step - loss: 0.0312 - accuracy: 0.9895\n",
      "Epoch 1/20\n",
      "35/35 [==============================] - 20s 579ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9897\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 20s 568ms/step - loss: 5.1655e-04 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9974\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 20s 571ms/step - loss: 3.3774e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9974\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 20s 574ms/step - loss: 4.8431e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9974\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 20s 575ms/step - loss: 3.0019e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 2.9905e-04 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 20s 575ms/step - loss: 2.5119e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 3.2044e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9974\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 20s 578ms/step - loss: 1.3388e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9948\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 20s 577ms/step - loss: 1.5772e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 20s 575ms/step - loss: 2.8974e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 21s 609ms/step - loss: 1.8719e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 23s 663ms/step - loss: 1.9411e-04 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9948\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 22s 624ms/step - loss: 1.7564e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 20s 582ms/step - loss: 1.9416e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 20s 581ms/step - loss: 1.9013e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 9.6482e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 20s 575ms/step - loss: 1.5302e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 20s 577ms/step - loss: 1.1789e-04 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9974\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 20s 575ms/step - loss: 1.4666e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9974\n",
      "27/27 [==============================] - 2s 71ms/step - loss: 0.0328 - accuracy: 0.9942\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 19s 586ms/step - loss: 9.4147e-05 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9981\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 19s 581ms/step - loss: 1.2239e-04 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9961\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 19s 581ms/step - loss: 1.4210e-04 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9961\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 19s 582ms/step - loss: 1.7290e-04 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 19s 582ms/step - loss: 5.0592e-04 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9981\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 19s 582ms/step - loss: 3.8086e-04 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9981\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 19s 583ms/step - loss: 1.5749e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 19s 585ms/step - loss: 2.4603e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9961\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 20s 596ms/step - loss: 9.3374e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9961\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 19s 583ms/step - loss: 1.2606e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9961\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 19s 583ms/step - loss: 2.5887e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9961\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 19s 583ms/step - loss: 8.5583e-04 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 19s 582ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.0810 - val_accuracy: 0.9748\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 19s 581ms/step - loss: 0.0339 - accuracy: 0.9874 - val_loss: 1.0181 - val_accuracy: 0.8450\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 19s 583ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0385 - val_accuracy: 0.9864\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 19s 580ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.6426 - val_accuracy: 0.8547\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 19s 583ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0310 - val_accuracy: 0.9884\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 19s 587ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 20s 605ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9981\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 20s 609ms/step - loss: 7.4271e-04 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9981\n",
      "27/27 [==============================] - 2s 72ms/step - loss: 0.0370 - accuracy: 0.9942\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 19s 616ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0106 - val_accuracy: 0.9984\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 19s 606ms/step - loss: 6.8410e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9969\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 19s 617ms/step - loss: 5.0544e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9953\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 20s 634ms/step - loss: 4.5819e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 19s 621ms/step - loss: 5.5075e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 19s 601ms/step - loss: 4.1059e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9969\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 18s 592ms/step - loss: 2.6808e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9969\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 18s 592ms/step - loss: 1.8387e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9969\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 19s 605ms/step - loss: 4.3721e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9953\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 19s 623ms/step - loss: 9.5012e-04 - accuracy: 0.9995 - val_loss: 0.0104 - val_accuracy: 0.9953\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 20s 641ms/step - loss: 4.0953e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9891\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 20s 646ms/step - loss: 6.1611e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9938\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 20s 647ms/step - loss: 9.9795e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9922\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 20s 634ms/step - loss: 2.8417e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "31/31 [==============================] - 19s 614ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 19s 599ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.6194 - val_accuracy: 0.8481\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 18s 590ms/step - loss: 0.0098 - accuracy: 0.9953 - val_loss: 0.1153 - val_accuracy: 0.9519\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 18s 590ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9907\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 19s 611ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9938\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 19s 613ms/step - loss: 8.8524e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9953\n",
      "27/27 [==============================] - 2s 74ms/step - loss: 0.0446 - accuracy: 0.9895\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 19s 646ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9935\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 19s 668ms/step - loss: 5.7327e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 20s 678ms/step - loss: 6.9929e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9987\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 19s 672ms/step - loss: 3.1084e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9987\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 19s 652ms/step - loss: 3.4918e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9974\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 18s 631ms/step - loss: 6.8962e-04 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9987\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 18s 612ms/step - loss: 4.3972e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9974\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 18s 606ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.0164 - val_accuracy: 0.9987\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 18s 606ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.0704 - val_accuracy: 0.9677\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 18s 609ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.0701 - val_accuracy: 0.9574\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 18s 627ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 1.6974 - val_accuracy: 0.7458\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 19s 647ms/step - loss: 0.0042 - accuracy: 0.9978 - val_loss: 0.0847 - val_accuracy: 0.9561\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 19s 669ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.0086 - val_accuracy: 0.9974\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 20s 674ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9974\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 19s 662ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0114 - val_accuracy: 0.9974\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 19s 643ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9961\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 18s 624ms/step - loss: 8.8946e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 18s 619ms/step - loss: 8.7708e-04 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9948\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 18s 608ms/step - loss: 5.1768e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9961\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 19s 657ms/step - loss: 6.2908e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9961\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 0.0604 - accuracy: 0.9884\n",
      "Epoch 1/20\n",
      "27/27 [==============================] - 18s 660ms/step - loss: 2.1324e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9978\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 18s 667ms/step - loss: 4.9525e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9978\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 18s 683ms/step - loss: 1.6130e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9978\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 18s 685ms/step - loss: 2.6096e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9967\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 18s 667ms/step - loss: 2.4659e-04 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9967\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 18s 658ms/step - loss: 1.7967e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9967\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 18s 651ms/step - loss: 9.1943e-04 - accuracy: 0.9994 - val_loss: 0.0085 - val_accuracy: 0.9978\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 17s 633ms/step - loss: 4.1253e-04 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9956\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 16s 611ms/step - loss: 1.8226e-04 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9978\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 17s 613ms/step - loss: 3.3694e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9956\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 17s 614ms/step - loss: 3.7309e-04 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9956\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 17s 612ms/step - loss: 2.1731e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9967\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 17s 611ms/step - loss: 2.9405e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9967\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 17s 636ms/step - loss: 4.6585e-04 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9978\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 17s 614ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9967\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 16s 610ms/step - loss: 0.0092 - accuracy: 0.9958 - val_loss: 0.2797 - val_accuracy: 0.9158\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 17s 611ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.4308 - val_accuracy: 0.8859\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 17s 612ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0392 - val_accuracy: 0.9878\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 16s 610ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9889\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 17s 612ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9900\n",
      "27/27 [==============================] - 2s 70ms/step - loss: 0.0713 - accuracy: 0.9791\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 16s 632ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0210 - val_accuracy: 0.9942\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 16s 636ms/step - loss: 5.2960e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9932\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 16s 644ms/step - loss: 6.1420e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9961\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 16s 649ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0253 - val_accuracy: 0.9932\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 16s 649ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9961\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 16s 652ms/step - loss: 4.4458e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9961\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 17s 666ms/step - loss: 5.5053e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9952\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 16s 633ms/step - loss: 5.9456e-04 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9971\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 16s 636ms/step - loss: 3.2917e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9981\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 16s 645ms/step - loss: 3.0466e-04 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9981\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 16s 654ms/step - loss: 2.5238e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9981\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 16s 652ms/step - loss: 2.0109e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9981\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 16s 642ms/step - loss: 2.9416e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9981\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 16s 630ms/step - loss: 2.7921e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 16s 630ms/step - loss: 2.8414e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9952\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 16s 628ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0103 - val_accuracy: 0.9971\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 16s 629ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.1802 - val_accuracy: 0.9457\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 16s 629ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 2.4518 - val_accuracy: 0.7461\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 16s 628ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 2.3758 - val_accuracy: 0.7316\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 16s 629ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9952\n",
      "27/27 [==============================] - 2s 71ms/step - loss: 0.0702 - accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "val_evaluate = []\n",
    "\n",
    "for validation in get_list(0, 0.4, 0.05):\n",
    "    history.append(model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split = validation, verbose=1))\n",
    "    val_evaluate.append(model.evaluate(X_test, y_test)[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
      "[99.18699264526367, 98.72241616249084, 98.95470142364502, 99.41927790641785, 99.41927790641785, 98.95470142364502, 98.83856177330017, 97.90940880775452, 98.83856177330017]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_list = get_list(0, 0.4, 0.05)\n",
    "\n",
    "print(val_list)\n",
    "print(val_evaluate)\n",
    "\n",
    "plt.plot(val_list, val_evaluate, 'ro-')\n",
    "plt.xlabel('validation')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n"
     ]
    }
   ],
   "source": [
    "idx = val_evaluate.index(max(val_evaluate))\n",
    "validation = val_list[idx]\n",
    "print(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 20s 583ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0500 - val_accuracy: 0.9871\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 20s 582ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0321 - val_accuracy: 0.9871\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9871\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 20s 580ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9922\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 20s 575ms/step - loss: 7.4831e-04 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9948\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 20s 573ms/step - loss: 6.6129e-04 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9922\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 20s 575ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0400 - val_accuracy: 0.9897\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 20s 574ms/step - loss: 6.6925e-04 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9922\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0345 - val_accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 20s 579ms/step - loss: 6.3914e-04 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9897\n",
      "27/27 [==============================] - 2s 72ms/step - loss: 0.0448 - accuracy: 0.9895\n",
      "Epoch 1/15\n",
      "35/35 [==============================] - 21s 589ms/step - loss: 5.1446e-04 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9897\n",
      "Epoch 2/15\n",
      "35/35 [==============================] - 21s 587ms/step - loss: 2.5993e-04 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9897\n",
      "Epoch 3/15\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 4.6497e-04 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9948\n",
      "Epoch 4/15\n",
      "35/35 [==============================] - 20s 577ms/step - loss: 4.8924e-04 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9948\n",
      "Epoch 5/15\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 1.8865e-04 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9948\n",
      "Epoch 6/15\n",
      "35/35 [==============================] - 20s 578ms/step - loss: 2.8608e-04 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9922\n",
      "Epoch 7/15\n",
      "35/35 [==============================] - 20s 577ms/step - loss: 1.0147e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9922\n",
      "Epoch 8/15\n",
      "35/35 [==============================] - 21s 589ms/step - loss: 3.3601e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9948\n",
      "Epoch 9/15\n",
      "35/35 [==============================] - 21s 603ms/step - loss: 2.0625e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9948\n",
      "Epoch 10/15\n",
      "35/35 [==============================] - 20s 577ms/step - loss: 9.7909e-05 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9948\n",
      "Epoch 11/15\n",
      "35/35 [==============================] - 20s 578ms/step - loss: 1.0435e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9922\n",
      "Epoch 12/15\n",
      "35/35 [==============================] - 21s 596ms/step - loss: 6.8296e-05 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9897\n",
      "Epoch 13/15\n",
      "35/35 [==============================] - 21s 592ms/step - loss: 1.7485e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9922\n",
      "Epoch 14/15\n",
      "35/35 [==============================] - 22s 619ms/step - loss: 1.9729e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9897\n",
      "Epoch 15/15\n",
      "35/35 [==============================] - 22s 629ms/step - loss: 1.8534e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9897\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.0507 - accuracy: 0.9861\n",
      "Epoch 1/20\n",
      "35/35 [==============================] - 22s 638ms/step - loss: 1.6590e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9922\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 21s 609ms/step - loss: 2.7352e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9922\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 21s 609ms/step - loss: 1.9403e-04 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9845\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 23s 650ms/step - loss: 7.8533e-05 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9897\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 23s 660ms/step - loss: 4.1102e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9871\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 22s 642ms/step - loss: 2.1589e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9871\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 23s 654ms/step - loss: 7.5628e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9871\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 22s 641ms/step - loss: 9.2555e-05 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 22s 617ms/step - loss: 5.2972e-04 - accuracy: 0.9995 - val_loss: 0.0217 - val_accuracy: 0.9922\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 21s 596ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 0.1952 - val_accuracy: 0.9483\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 20s 585ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9819\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 0.0526 - val_accuracy: 0.9845\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 20s 577ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.3089 - val_accuracy: 0.9432\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 20s 583ms/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 0.0423 - val_accuracy: 0.9922\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 21s 587ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0382 - val_accuracy: 0.9845\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 20s 584ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0493 - val_accuracy: 0.9845\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 20s 580ms/step - loss: 5.5752e-04 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9922\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 20s 579ms/step - loss: 2.7650e-04 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9922\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 20s 579ms/step - loss: 1.9268e-04 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9897\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 20s 576ms/step - loss: 1.7510e-04 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9897\n",
      "27/27 [==============================] - 2s 72ms/step - loss: 0.0636 - accuracy: 0.9872\n",
      "Epoch 1/25\n",
      "35/35 [==============================] - 20s 578ms/step - loss: 1.3668e-04 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9897\n",
      "Epoch 2/25\n",
      "35/35 [==============================] - 20s 577ms/step - loss: 3.2084e-04 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9897\n",
      "Epoch 3/25\n",
      "35/35 [==============================] - 20s 583ms/step - loss: 9.3001e-04 - accuracy: 0.9995 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
      "Epoch 4/25\n",
      "35/35 [==============================] - 21s 596ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0740 - val_accuracy: 0.9845\n",
      "Epoch 5/25\n",
      "35/35 [==============================] - 21s 600ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.1031 - val_accuracy: 0.9716\n",
      "Epoch 6/25\n",
      "35/35 [==============================] - 21s 610ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 0.0730 - val_accuracy: 0.9819\n",
      "Epoch 7/25\n",
      "35/35 [==============================] - 24s 694ms/step - loss: 2.7342e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9897\n",
      "Epoch 8/25\n",
      "35/35 [==============================] - 26s 743ms/step - loss: 2.8491e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9897\n",
      "Epoch 9/25\n",
      "35/35 [==============================] - 23s 653ms/step - loss: 5.7626e-04 - accuracy: 0.9995 - val_loss: 0.0378 - val_accuracy: 0.9871\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 23s 648ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.1083 - val_accuracy: 0.9638\n",
      "Epoch 11/25\n",
      "35/35 [==============================] - 22s 628ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
      "Epoch 12/25\n",
      "35/35 [==============================] - 25s 718ms/step - loss: 7.2785e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 13/25\n",
      "14/35 [===========>..................] - ETA: 13s - loss: 3.7247e-04 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "epoch_evaluate = []\n",
    "\n",
    "for epoch in range(10, 50, 5):\n",
    "    history.append(model.fit(X_train, y_train, batch_size=64, epochs=epoch, validation_split = validation, verbose=1))\n",
    "    epoch_evaluate.append(model.evaluate(X_test, y_test)[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = get_list(10, 50, 5)\n",
    "    \n",
    "print(epoch_list)\n",
    "print(epoch_evaluate)\n",
    "\n",
    "plt.plot(epoch_list, epoch_evaluate, 'ro-')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = epoch_evaluate.index(max(epoch_evaluate))\n",
    "epoch = epoch_list[idx]\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"end를 포함하는 리스트 반환\n",
    "    2의 배수만큼 스텝을 밟음\"\"\"\n",
    "\n",
    "def double_range(start, end): \n",
    "    lst = []\n",
    "    st = start\n",
    "    try:\n",
    "        while st <= end:\n",
    "            lst.append(st)\n",
    "            st *= 2\n",
    "    except ZeroDivisionError:\n",
    "        print('0으로 나눌 수 없습니다.')\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "batch_evaluate = []\n",
    "\n",
    "for batch in double_range(2, 1024):\n",
    "    history.append(model.fit(X_train, y_train, batch_size=batch, epochs=epoch, validation_split = validation, verbose=1))\n",
    "    batch_evaluate.append(model.evaluate(X_test, y_test)[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(double_range(2, 1024), batch_evaluate, 'ro-')\n",
    "plt.label('batch size')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = double_range(2, 1024)\n",
    "\n",
    "idx = batch_evaluate.index(max(batch_evaluate))\n",
    "batch = batch_list[idx]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch, epochs=epoch, validation_split=validation, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.around(y_pred)\n",
    "print(y_pred.shape)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print('confusion matrix 결과')\n",
    "print(confusion_matrix(y_test, y_pred, labels=[0, 1])) # 0 : 광고 1: 비광고\n",
    "\n",
    "print('precision 개별값')\n",
    "print(list(map('{:2.2f}%'.format, precision_score(y_test, y_pred, average=None) * 100))) # precision 개별 값\n",
    "print('recall 개별값')\n",
    "print(list(map('{:2.2f}%'.format, recall_score(y_test, y_pred, average=None) * 100)))\n",
    "\n",
    "print('precision 평균값')\n",
    "print('{:2.2f}%'.format(precision_score(y_test, y_pred, average='macro') * 100)) # precision 평균 값\n",
    "print('recall 평균값')\n",
    "print('{:2.2f}%'.format(recall_score(y_test, y_pred, average='macro') * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"정확도 : %.2f \" %(model.evaluate(X_test, y_test)[1]))\n",
    "print(\"정확도 : \" '{:2.2f}%'.format(model.evaluate(X_test, y_test)[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./binary_model_saved.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'] )\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['acc', 'val_acc'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_cnn",
   "language": "python",
   "name": "train_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
