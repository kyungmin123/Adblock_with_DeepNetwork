# 5강. 훈련 노하우를 배웁니다

## 05-1. 검증 세트를 나누고 전처리 과정을 배웁니다
: 5강에서는 4강에서 다루었던 훈련 세트와 테스트 세트 중 '테스트 세트'의 사용 방법에 대해 조금 더 깊이 알아보자. 목표는 **어느 데이터 세트에만 치우친 모델을 만들지 않는 것**이다 

### 테스트 세트로 모델을 튜닝합니다

**로지스틱 회귀로 모델 훈련하고 평가하기**

: cancer 데이터 세트를 읽어 들여 train set/test set 으로 나눕니다

```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# 데이터 셋 로드 및 train/test set으로 분리
cancer = load_breast_cancer()
x = cancer.data
y = cancer.target
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)
```

- train_test_split(arrays, test_size, train_size, random_state, shuffle, stratify)

  - arrays : 분할시킬 데이터를 입력

  - Train/Test_size : 훈련/테스트 데이터 셋의 비율(int값을 넣을 경우 갯수)

  - random_state : 데이터 분할시 셔플이 이루어지는데 이를 위한 시드값

    - 해당 값을 설정할 경우 결과가 일정하게 나옴

  - shuffle : 셔플 여부 설정(default = True)

  - Stratify : 지정한 data의 비율을 유지

    - 만약 label set Y가 25%의 0과 75%의 1로 이루어진 binary set일 때, stratify = y로 설정할 경우

      : 나누어진 데이터 셋들도 0과 1의 비율을 각각 25%, 75%로 유지한 채 분할이 됨

```python
# 모델 훈련 및 평가
from sklearn.linear_model import SGDClassifier
sgd = SGDClassfier(loss = 'log', random_state = 42)
sgd.fit(x_train, y_train)
sgd.score(x_test, y_test)
```

- 테스트 세트에서의 정확도는 약 **83%**이다
  - 이 성능이 만족스럽지 않을 경우 `log` 말고 다른 손실함수를 사용해도 됨
- loss와 같은 매개변수의 값은 가중치나 절편처럼 알아서 학습되는 것이 아님
  - 즉 사용자가 직접 선택해야 함
  - 이런 값을 **하이퍼파라미터(hyperparameter)**라고 부름
- loss의 값을 바꾸면 성능이 정말 좋아지는지 확인해 보자

**서포트 벡터 머신으로 모델 훈련하고 평가하기**

: SGDClassifier 클래스의 loss 매개변수를 log에서 hinge로 바꾸면 선형 서포트 벡터 머신 문제를 푸는 모델이 만들어짐

- SVM이란? 훈련 데이터의 클래스를 구분하는 경계선을 찾는 작업으로 분류과제에서 사용할 수 있는 강력한 ML 지도학습 모델

  - [사진 링크](http://hleecaster.com/ml-svm-concept/)

  <img src="/Users/mac/Library/Application Support/typora-user-images/image-20210207113806774.png" alt="image-20210207113806774" style="zoom:30%;" />

  ```python
  from sklearn.linear_model import SGDClassifier
  sgd = SGDClassifier(loss = 'hinge', random_state = 42)
  sgd.fit(x_train, y_train)
  sgd.score(x_test, y_test)
  ```

  - 이 경우 **93*%**의 정확도가 나옴 : 로지스틱 회귀로 만든 모델의 성능보다 더 좋음
    - 성능이 만족스럽지 않을 경우 이렇게 loss 매개변수에 다른 값을 적용했듯이 SGDClassifier 클래스의 다른 매개변수들을 바꿔보면 됨
    - 이런 작업을 **모델을 튜닝한다**고 함
  - 그런데 사실, 이 모델은 실전에서는 좋은 성능을 내지 못할 확률이 높음



### 테스트 세트로 모델을 튜닝하면 실전에서 좋은 성능을 기대하기 어렵습니다
: test set은 실전에 투입된 모델의 성능을 측정하기 위해 사용되는데 지금처럼 test set을 가지고 모델을 튜닝할 경우, '테스트 세트에 대해서만 좋은 성능을 보여주는 모델'이 만들어진다 즉 실전에서는 test set과 같지 않은 다양한 데이터가 존재할텐데, 당연히 같은 성능을 기대하기 어렵다. 이런 현상을 'test set의 정보가 모델에 새어 나갔다'라고 말한다.    

- 정리하면 test set로 모델을 튜닝하면 test set의 정보가 모델에 새어 나가므로 모델의 일반화 성능이 왜곡된다
  - 이 경우 ML에서 낙과적으로 성능을 추정한다는 표현을 쓰기도 함

### 검증 세트(Validation set)를 준비합니다
: 즉, 모델을 튜닝할 때 test set을 사용하지 않으면 된다. 하지만 모델을 튜닝하려면 성능 점수가 필요하므로, 테스트 세트는 모델 튜닝을 모두 마치고 실전에 투입하기 전에 딱 한 번만 사용하는 것이 좋다 즉 모델 튜닝을 위한 세트는 따로 준비해야 한다. 

- 모델을 튜닝하는 용도의 set은 validation set라고 하며 전체 데이터 셋이 훈련:검증:테스트 셋으로 구성된다
  - 예:) train set : validation set : test set = 6 : 2 : 2

- 해당 방법을 이용하여 모델을 다시 훈련해보자

1. data set 준비하기

   : 이번에도 위스콘신 유방암 데이터 사용

   ```python
   from sklearn.datasets import load_breast_cancer
   from sklearn.model_selection import train_test_split
   
   cancer = load_breast_cancer()
   x = cancer.data
   y = cancer.target
   x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)
   ```

   

2. validation set 분할하기

   - Train set : validation set : test set = 6 : 2 : 2
     - Train set : test set = 8 : 2로 선 분리후
     - 분리된 train set을 다시 8 : 2로 나누어 validation set을 만든다 

   ```python
   x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, stratify = y_train, test_size = 0.2, random_state = 42)
   ```

   

3. validation set을 사용해 모델 평가하기

   ```python
   sgd = SGDClassifier(loss = 'log', random_state = 42)
   sgd.fit(x_train, y_train)
   sgd.score(x_val, y_val)
   ```

   - 이 경우 **69%**의 성능이 나온다
     - 앞의 실습보다 낮은 결과가 나온 이유는 train set의 크기가 줄어들었기 때문
   - 사실 해당 데이터(위스콘신 유방암 data set)의 샘플 개수는 적은 편임
     - 따라서 validation set의 비율이나 random_state 매개변수의 값을 조금만 조정해도 성능 평가 점수는 크게 변함
     - 데이터 양이 너무 적은 경우에는 따라서 validation set을 나누지 않고 교차 검증(cross validation)방법을 사용
   - 하지만 요즘은 대량의 train set을 손쉽게 모을 수 있음
     - 10만개의 데이터가 있다면 8 : 1 : 1 정도로 분할
     - 100만개 이상의 데이터는 98 : 1: 1 정도의 비율로 샘플을 분할

### 데이터 전처리와 특성의 스케일을 알아봅니다

: 사이킷런과 같은 머신러닝 패키지에 준비되어 있는 데이터는 대부분 실습을 위한 것이므로 잘 가공되어 있으나 실전에서 수집된 데이터는 그렇지 않다. 누락된 값이 있을 수도 있고 데이터의 형태가 균일하지 않을 수도 있다. 이런 데이터들을 그대로 사용하면 제대로 된 결과를 얻을 수 없으므로, 이런 경우 데이터를 적절히 가공하는 **데이터 전처리(data preprocessing)** 과정이 필요하다. 이번에는 데이터 전처리에 대해 알아보자

**특성의 스케일은 알고리즘에 영향을 줍니다.**

: 잘 정리된 데이터도 전처리를 해야하는 경우가 있음

- 특성의 스케일이 다른 경우

  - 특성의 스케일이란? 어떤 특성이 가지고 있는 값의 범위를 말한다. 

    예:)  사과의 특성의 경우 당도는 1 부터 10까지의 범위를 가지는 반면 무게는 500 부터 1000을 가지는 경우 

    - 이 경우 두 특성의 스케일 차이가 크다고 한다

- 경사하강법은 스케일에 민감한 알고리즘임
  - [이유 참고 블로그](https://mazdah.tistory.com/833)
  - 해당 책에서 소개하는 신경망 알고리즘들은 모두 경사하강법 사용
    - 따라서 특성의 스케일을 맞추는 등의 전처리 과정이 필요함

### 스케일을 조정하지 않고 모델을 훈련해볼까요?
: 지금부터는 특성의 스케일이 서로 다른 데이터를 이용하여 모델을 훈련하면 가중치가 어떻게 변하는지 살펴보자.

[colab ch05-1 code 참고](https://colab.research.google.com/drive/16lVLa-smS0mp8dhYSak5EyVTOmsZUTX5#scrollTo=yxyVk5_Te0zL)

### 스케일을 조정해 모델을 훈련합니다
: 스케일을 조정하는 방법은 많지만 신경망에서 자주 사용하는 스케일 조정 방법 중 하나는 표준화이다. 표준화는 특성 값에서 평균을 빼고 표준 편차로 나누면 된다. 표준화를 하면 평균이 0이고 분산이 1인 특성이 만들어진다. 표준화 공식은 다음과 같다.  
$$
z = \frac {x - μ}{s}
$$

사이킷런에는 표준화를 위한 StandardScaler 클래스가 준비되어 있지만 여기서는 학습을 위해 직접 표준화를 구현해보자

[colab ch05-1 code 참고](https://colab.research.google.com/drive/16lVLa-smS0mp8dhYSak5EyVTOmsZUTX5#scrollTo=yxyVk5_Te0zL)


## 05-2. 과대적합과 과소적합을 알아봅니다
: 여기서는 훈련 세트와 검증 세트에 대한 모델의 성능에 대해 조금 더 깊이 고찰해 보도록 하자.  train set와 validation set는 모델의 과대 적합, 과소 적합이라는 문제와 깊은 연관이 있다. 

### 학습 곡선을 통해 과대적합과 과소 적합(underfitting)을 알아봅니다.

**Train set의 크기와 과대적합, 과소적합 분석하기**

**과대 적합 : overfitting**

- 모델이 train set에서는 좋은 성능을 내지만 validation set에서는 낮은 성능을 내는 경우
- 즉 두 set에서 측정한 성능의 간격이 클 경우이며 이 경우 모델을 **분산이 크다**라고 말함
  -  예로, train set의 정확도가 99%이고 validation set의 정확도가 80% 수준이라면 과대 적합을 의심할 수 있음
- 원인 : train set에 충분히 다양한 패턴의 샘플이 포함되지 않은 경우
  - 해결 방법 : 더 많은 훈련 샘플을 모아 validation set의 성능을 향상시킬 수 있음
  - 만약 현실적인 문제로 train set을 더 많이 모을 수 없는 경우
    - 해결 방법: 모델이 train set에 집착하지 않도록 가중치를 제한할 수 있음(=모델의 복잡도를 낮춘다)

**과소 적합 : underfitting**

- train set와 validation set의 성능에는 차이가 크지 않지만 모두 낮은 성능을 내는 경우를 말함
- 즉 두 set에서 측정한 성능의 간격은 점점 가까워지나 성능 자체가 낮은 경우이며 이 모델을 **편향이 크다**라고 말함
- 원인 : 모델이 충분히 복잡하지 않아 train set에 있는 패턴을 모두 잡아내지 못하는 현상
  - 해결 방법 : 복잡도가 더 높은 모델을 사용하거나 가중치의 규제를 완화하는 것



**에포크 손실 함수의 그래프로 과대적합과 과소적합 분석하기**

: 4장에서 살펴본 에포크에 대한 손실 함수의 그래프를 사용하여 과대적합과 과소적합을 분석하기도 한다. 따라서 에포크에 대한 손실 함수의 그래프를 학습 곡선이라고 부르기도 한다.  `에포크와 손실 함수에 대한 그래프`와 `에포크와 정확도에 대한 그래프`를 통해 과대적합과 과소적합을 분석해보자

1. `에포크과 손실 함수에 대한 그래프`
   - train set 손실을 에포크가 진행될 수록 감소
   - validation set의 손실을 에포크의 획수가 최적점을 지나면 오히려 상승
   - **최적점 이후에도 계속해서 모델을 학습시키면 모델이 train set에 더 밀착하여 학습을 하게 됨**
     - 즉, 최적점 이후부터는 모델이 과대적합되기 시작하는 것임
     - 반대로 최적점 이전에 학습을 중지시킬 경우 과소적합이 됨
2. `에포크와 정확도에 대한 그래프`
   - 1번의 그래프와 비교해보면 그래프가 뒤집혀 있을 뿐 해석은 동일함

**모델 복잡도와 손실 함수의 그래프로 과대적합과 과소적합 분석하기**
: 가로축에 에포크 대신 모델 복잡도를 넣어 표현하기도 한다. 

- 모델 복잡도란? 모델이 가진 학습 가능한 가중치의 개수로, 이 개수가 많아질수록 복잡도가 높은 모델이 만들어진다   

  - 모델이 복잡하다고 무조건 좋은 것은 아니다.

    : 예를 들어 모델이 훈련 세트에만 잘 맞는 형태로 만들어지면 훈련 세트에서만 좋은 성능을 냄(과대 적합이 이에 해당)

### 적절한 편향-분산 트레이오프를 선택합니다
- bias-variance tradeoff

  - 정의 : **과소적합된 모델(=편향되었다)**과 **과대적합된 모델(=분산이 크다)** 사이의 관계

  - trade off란? '하나를 얻기 위해서는 다른 하나를 희생해야 함'라는 의미로 사용됨. 
    - 즉 편향을 줄이면(훈련 세트의 성능을 높이면) 분산이 커지고(검증 세트와 성능 차이가 커지고) 반대의 경우 분산을 줄이면 편향이 커지는 것을 말한다. 
    - 따라서 우리는 분산, 편향이 너무 커지지 않도록 중간 지점을 선택해야 함
      -  이러한 행위를 '적절한 편향-분산 트레이드오프를 선택했다'라고 함
      -  경사 하강법의 에포크 횟수에 대한 모델의 손실을 그래프로 그려 '적절한 편향-분산 트레이드오프'를 선택해보자

[colab ch05-2 code 참고](https://colab.research.google.com/drive/16lVLa-smS0mp8dhYSak5EyVTOmsZUTX5#scrollTo=yxyVk5_Te0zL)



## 05-3. 규제 방법을 배우고 단일층 신경망에 적용합니다
: 05-2에서 과대적합을 설명하면서 과대적합을 해결하는 대표적인 방법 중 하나로 가중치 규제를 소개했다. **가중치 규제란 가중치의 값이 커지지 않도록 제한하는 기법으로 가중치를 규제하면 모델의 일반화 성능이 올라가게 된다**
- 하나의 샘플 데이터에 대해 서로 다른 두 모델이 점을 어느정도 잘 표현하고 있다고 했을 때 둘 중 **경사가 더 완만한 그래프가 성능이 좋다고 평가한다**
- 샘플 데이터를 정확이 관통하는 모델일 경우(7개중 6개는 관통하나 1개는 빗나감) 좋은 성능을 가진 모델이라고 평가하지 않는다. 
  - 모델이 몇 개의 데이터에 집착하면 새로운 데이터에 적응을 하지 못하기 때문
    - 이것을 '모델이 일반화되지 않았다'고 말한다
      : 이 경우 규제를 사용하여 가중치를 제한하면 모델이 몇 개의 데이터에 집착하지 않게 되므로 일반화 성능을 높일 수 있음
    - 대표적인 규제 기법인 L1,L2 규제를 살펴보자

### L1규제를 알아봅니다
- 손실 함수에 가중치의 절대값인 L1 노름을 추가하는 것으로, **가중치의 절댓값을 손실 함수에 더한 것**임

- 로지스틱 손실 함수 L
  $$
  L = -(ylog(a) + (1-y)log(1-a))
  $$

- L1 규제
  $$
  L = -(ylog(a) + (1-y)log(1-a))+α \sum\limits_{i=1}^{n} |w_i|
  $$

  - α : L1 규제의 양을 조절하는 하이퍼파라미터

    - α의 값이 클 경우 : 전체 손실 함수의 값이 커지지 않도록 ω 값의 합이 작아져야 함(**규제가 강해졌다**)
    - α의 값이 작은 경우 : ω의 합이 커져도 손실 함수의 값이 큰 폭으로 커지지 않음(**규제가 약해짐**)

    

### L1 규제의 미분(PASS)

- 미분을 하는 이유

  경사 하강법으로 가중치를 업데이트하기 위하여 L1규제를 적용한 로지스틱 손실 함수를 미분해야 함

- 미분 과정

  1. |ω|를 ω에 대해 미분할 경우 부호만 남게 되므로 ω의 부호라는 의미로 sign(ω)라고 표현한다.  이 경우 L1규제를 적용한 손실함수의 도함수는 다음과 같다   

  $$
  \frac {∂}{∂w}L = -(y-a) x + αsign(w)
  $$



**회귀 모델에 L1규제를 추가한 것을 라쏘 모델이라고 한다**

- 회귀 모델에도 같은 원리를 적용하여 손실 함수(제곱 오차)에 L1 규제를 적용할 수 있다

  - 이런 모델을 Lasso라고 부름

    - 라쏘는 일부 가중치를 0으로 만들 수 있어 특성을 선택하는 효과를 얻을 수 있음

  - 사이킷런에서 sklearn.linear_model.Lasso 클래스에서 라쏘 모델을 제공한다. 

    (SGDClassifier클래스에서는 penalty 매개변수 값을 l1으로 지정하는 방법으로 L1규제를 적용할 수 있다)

- 단, 미분 결과에서 알 수 있듯이 L1규제는 규제 하이퍼파라미터 a에 많이 의존함
  - 즉,  가중치의 크기에 따라 규제의 양이 변하지 않으므로 규제 효과가 좋다고 할 수 없다. (더 찾아보기)
  - 다음으로 규제 효과가 좋아 널리 사용되는 L2규제에 대해 알아보자

### L2 규제를 알아봅니다

: L2 규제는 손실 함수에 가중치에 대한 L2 노름의 제곱을 더합니다

- L2 노름은 다음과 같이 정의 됨
  $$
  ||w||_2 = \sqrt {\sum\limits_{i=1}^{n} |w_i|^2}
  $$

- 손실함수에 L2노름의 제곱을 더하면 L2 규제가 됨
  $$
  L = -(ylog(a) + (1-y)log(1-a))+ \frac {1}{2}α\sqrt {\sum\limits_{i=1}^{n} |w_i|^2}
  $$
  

### L2 규제의 미분(PASS)
: 로지스틱 손실 함수의 미분은 이전과 동일하게 진행하며, L2 규제를 미분하면 간단히 가중치 벡터 w만 남는다. 
**(∂/∂w)L = -(y-a) * x + a * w**
L2 규제는 그레디언트 계산에 가중치의 값 자체가 포함되므로 가중치의 부호만 사용하는 L1 규제 보다 조금 더 효과적이다. 또한 L2 규제는 가중치를 완전히 0으로 만들지 않는다. 가중치가 0일 경우 특성을 제외하는 효과는 있으나 모델의 복잡도가 떨어진다. 이러한 이유로 L2 규제를 널리 사용한다

- 회귀 모델에 L2 규제를 적용한 것을 릿지 모델이라고 합니다
: 사이킷런에서 sklearn.linear_model.Ridge 클래스에서 릿지 모델을 제공한다.   SGDClassifier클래스에서는 penalty 매개변수 값을 l2으로 지정하는 방법으로 L2규제를 적용할 수 있다

### L1규제와 L2규제 정리
: 다음은 L1, L2 규제를 경사하강법에 추가하는 방법을 정리한것이다
1. L1 규제 : 그레디언트에서 alpha에 가중치의 부호를 곱하여 그레디언트에 더함
**w_grad += alpha * np.sign(w)**
2. L2규제 : 그레디언트에서 alpha에 가중치를 곱하여 그레디언트에 더함  
**w_grad += alpha * w**

### 로지스틱 회귀에 규제를 적용합니다
[colab ch05-3 code 참고](https://colab.research.google.com/drive/16lVLa-smS0mp8dhYSak5EyVTOmsZUTX5#scrollTo=yxyVk5_Te0zL)


## 05-4. 교차 검증을 알아보고 사이킷런으로 수행해 봅니다
: 05-1절에서는 전체 데이터 세트의 샘플 개수가 많지 않을 때 검증 세트를 훈련 세트에서 분리하느라 훈련 세트의 샘플 개수가 줄어들어 모델을 훈련시킬 데이터가 부족해지는 경우를 경험함

- 이 경우에 교차 검증을 사용

### 교차 검증(Cross validation)의 원리를 알아봅니다
- 교차 검증은 전체 데이터 세트를 8 : 2로 나눈 다음 8에 해당 하는 훈련 세트를 다시 k개의 폴드로 나누어 폴드를 1번씩 검증에 사용하고 나머지 폴드를 훈련에 사용하는 방식이다.   
- 이때 교차검증은 훈련 세트를 k개의 폴드로 나누는 특징이 있으므로 k-폴드 교차 검증이라고 부른다.  이 방식은 모든 훈련 세트가 평가에 1번씩 사용되므로 검증 점수가 안정적이며 기존의 훈련 방법보다 더 많은 데이터로 훈련할 수 있다. 

### k-폴드 교차 검증을 구현합니다
[colab ch05-4 code 참고](https://colab.research.google.com/drive/16lVLa-smS0mp8dhYSak5EyVTOmsZUTX5#scrollTo=yxyVk5_Te0zL)


