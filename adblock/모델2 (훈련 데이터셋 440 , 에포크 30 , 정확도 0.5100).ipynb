{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import shutil\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_file_path='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\advertisement' # 일차적으로 수집한 광고 이미지\n",
    "os.makedirs(ad_file_path,exist_ok=True)\n",
    "ad_file_dir=os.listdir(ad_file_path)\n",
    "\n",
    "non_file_path='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\non_advertisement' # 일차적으로 수집한 비광고 이미지\n",
    "os.makedirs(non_file_path,exist_ok=True)\n",
    "non_file_dir=os.listdir(non_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더의 파일 개수를 구하는 함수\n",
    "def num_of_files(dir):\n",
    "    x=0\n",
    "    for pack in os.walk(dir):\n",
    "        for f in pack[2]:\n",
    "            x+=1\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset'\n",
    "os.makedirs(dataset,exist_ok=True)\n",
    "dataset_dir=os.listdir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\training_set'\n",
    "os.makedirs(train,exist_ok=True)\n",
    "train_dir=os.listdir(train)\n",
    "\n",
    "valid='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\validation_set'\n",
    "os.makedirs(valid,exist_ok=True)\n",
    "valid_dir=os.listdir(valid)\n",
    "\n",
    "test='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\testing_set'\n",
    "os.makedirs(test,exist_ok=True)\n",
    "test_dir=os.listdir(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\training_set\\\\ad'\n",
    "os.makedirs(train_ad,exist_ok=True)\n",
    "train_ad_dir=os.listdir(train_ad)\n",
    "\n",
    "train_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\training_set\\\\non'\n",
    "os.makedirs(train_non,exist_ok=True)\n",
    "train_non_dir=os.listdir(train_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\validation_set\\\\ad'\n",
    "os.makedirs(valid_ad,exist_ok=True)\n",
    "valid_ad_dir=os.listdir(valid_ad)\n",
    "\n",
    "valid_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\validation_set\\\\non'\n",
    "os.makedirs(valid_non,exist_ok=True)\n",
    "valid_non_dir=os.listdir(valid_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\testing_set\\\\ad'\n",
    "os.makedirs(test_ad,exist_ok=True)\n",
    "test_ad_dir=os.listdir(test_ad)\n",
    "\n",
    "test_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\testing_set\\\\non'\n",
    "os.makedirs(test_non,exist_ok=True)\n",
    "test_non_dir=os.listdir(test_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "\n",
    "for file in train_ad_dir:\n",
    "    try:\n",
    "        os.rename(train_ad+'\\\\'+file,ad_file_path+'\\\\'+str(i)+'.jpg')\n",
    "        i+=1\n",
    "    except FileExistsError:\n",
    "        i+=1\n",
    "        continue\n",
    "        \n",
    "if(os.path.exists(ad_file_path) and num_of_files(ad_file_path)>0):\n",
    "    for file in test_ad_dir:\n",
    "        try:\n",
    "            os.rename(test_ad+'\\\\'+file,ad_file_path+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i+=1\n",
    "            continue      \n",
    "            \n",
    "if(os.path.exists(ad_file_path) and num_of_files(ad_file_path)>0):\n",
    "    for file in valid_ad_dir:\n",
    "        try:\n",
    "            os.rename(valid_ad+'\\\\'+file,ad_file_path+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i+=1\n",
    "            continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=1\n",
    "\n",
    "for file in train_non_dir:\n",
    "    try:\n",
    "        os.rename(train_non+'\\\\'+file,non_file_path+'\\\\'+str(j)+'.jpg')\n",
    "        j+=1\n",
    "    except FileExistsError:\n",
    "        j+=1\n",
    "        continue\n",
    "        \n",
    "if(os.path.exists(non_file_path) and num_of_files(non_file_path)>0):\n",
    "    for file in test_non_dir:\n",
    "        try:\n",
    "            os.rename(test_non+'\\\\'+file,non_file_path+'\\\\'+str(j)+'.jpg')\n",
    "            j+=1\n",
    "        except FileExistsError:\n",
    "            j+=1\n",
    "            continue      \n",
    "            \n",
    "if(os.path.exists(non_file_path) and num_of_files(non_file_path)>0):\n",
    "    for file in valid_non_dir:\n",
    "        try:\n",
    "            os.rename(valid_non+'\\\\'+file,non_file_path+'\\\\'+str(j)+'.jpg')\n",
    "            j+=1\n",
    "        except FileExistsError:\n",
    "            j+=1\n",
    "            continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_ad'\n",
    "os.makedirs(new_ad,exist_ok=True)\n",
    "new_ad_dir=os.listdir(new_ad)\n",
    "\n",
    "new_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_non'\n",
    "os.makedirs(new_non,exist_ok=True)\n",
    "new_non_dir=os.listdir(new_non)\n",
    "\n",
    "\n",
    "if(os.path.exists(train_ad) and num_of_files(new_ad)>0):\n",
    "    i=num_of_files(train_ad)+1\n",
    "    for data in new_ad_dir:\n",
    "        try:\n",
    "            os.rename(new_ad+'\\\\'+data,train_ad+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileNotFoundError:\n",
    "            print(\"FileNotFoundError!\")\n",
    "            break\n",
    "\n",
    "if(os.path.exists(train_non) and num_of_files(new_non)>0):\n",
    "    j=num_of_files(train_non)+1\n",
    "    for data in new_non_dir:\n",
    "        try:\n",
    "            os.rename(new_non+'\\\\'+data,train_non+'\\\\'+str(j)+'.jpg')\n",
    "            j+=1\n",
    "        except FileNotFoundError:\n",
    "            print(\"FileNotFoundError!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새 데이터를 추가하고자 할 때, new_ad , new_non 폴더에 담았다가 train_ad , train_non 폴더로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[339 177  75  17 231 245 154 237 245 127 230  75 330 332 309 259 161 150\n",
      " 140  76   2 147 281  12 297 333 315  23 291 181 121 180 214 306  25 256\n",
      " 114 328 124 263 256 244 343 167 139 281 279 318 191 223 148 262 257  86\n",
      " 218 174 298 245 131  82 157 316 329 142 304 316  26 145  27  60 310 240\n",
      " 165 279 196  58  51 292 277 165 191 261  92 190 340]\n",
      "[  4 282  17 286 138 179 251 281 203 312  57 105  48 205 112  49 133 344\n",
      "  89 254  78 302 233 284  32   2 177 209 104  15 248  90 231 123 302  95\n",
      "  50 307   9 103  22 259 187 294 263 105 174 175 326 301 183 252 210 212\n",
      "  60  97 329 147 116 283  20 333 146 189 172  73 191 273 326  97 118 229\n",
      "  16 289 142 144 207 124  21 302 176 176 204 226 185 202]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "random_index_ad_arr=np.random.randint(1,num_of_files(ad_file_path)+1,size=num_of_files(ad_file_path)//4)\n",
    "random_index_non_arr=np.random.randint(1,num_of_files(non_file_path)+1,size=num_of_files(non_file_path)//4)\n",
    "\n",
    "print(random_index_ad_arr)\n",
    "print(random_index_non_arr)\n",
    "\n",
    "i=1\n",
    "if(os.path.exists(ad_file_path) and num_of_files(ad_file_path)>0):\n",
    "    for k in random_index_ad_arr:\n",
    "        try:\n",
    "            os.rename(ad_file_path+'\\\\'+str(k)+'.jpg',test_ad+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(test_ad)+1\n",
    "            continue  \n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            i=num_of_files(test_ad)+1\n",
    "            continue\n",
    "            \n",
    "j=1\n",
    "if(os.path.exists(non_file_path) and num_of_files(non_file_path)>0):\n",
    "    for k in random_index_non_arr:\n",
    "        try:\n",
    "            os.rename(non_file_path+'\\\\'+str(k)+'.jpg',test_non+'\\\\'+str(j)+'.jpg')\n",
    "            j+=1\n",
    "        except FileExistsError:\n",
    "            j=num_of_files(test_non)+1\n",
    "            continue \n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            j=num_of_files(test_non)+1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advertisement 폴더와 non_advertisement 폴더에서 각 파일 수의 1/4만큼 난수를 생성하고,\n",
    "그 난수에 해당하는 ad 파일과 non 파일을 각각 test_ad 폴더와 test_non 폴더로 이동시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208 261  49 121 189  99 242 203 111 254 234 254 247 123 239  85 149 205\n",
      " 185 170 134 230 275  51 237  49 262  81 249 269 241 272  29 138 134 236\n",
      " 119 231 251 219 123 161 113  64 208 182 122  72  34   9  59 104 127 108\n",
      "  65 154 221 207   6 172  19 246 255 133 163  51 145 228]\n",
      "[  2   2  28 162 247  33 195 222  68   2  66 208 162  50  34 206 247 246\n",
      " 184 230 126  82 108   4  95  39 194 258 221  81 190 238 121  11  69  29\n",
      " 145  35  42   1 185 159   2 194  37 119 251 182 260 264 161 182  95  11\n",
      " 152 237 227 211  91 218 115 231 132 155 203 239]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(21)\n",
    "random_index_ad_arr=np.random.randint(1,num_of_files(ad_file_path)+1,size=num_of_files(ad_file_path)//4)\n",
    "random_index_non_arr=np.random.randint(1,num_of_files(non_file_path)+1,size=num_of_files(non_file_path)//4)\n",
    "\n",
    "print(random_index_ad_arr)\n",
    "print(random_index_non_arr)\n",
    "\n",
    "i=1\n",
    "if(os.path.exists(ad_file_path) and num_of_files(ad_file_path)>0):\n",
    "    for k in random_index_ad_arr:\n",
    "        try:\n",
    "            os.rename(ad_file_path+'\\\\'+str(k)+'.jpg',valid_ad+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(valid_ad)+1\n",
    "            continue  \n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            i+=1\n",
    "            continue\n",
    "            \n",
    "j=1\n",
    "if(os.path.exists(non_file_path) and num_of_files(non_file_path)>0):\n",
    "    for k in random_index_non_arr:\n",
    "        try:\n",
    "            os.rename(non_file_path+'\\\\'+str(k)+'.jpg',valid_non+'\\\\'+str(j)+'.jpg')\n",
    "            j+=1\n",
    "        except FileExistsError:\n",
    "            j=num_of_files(valid_non)+1\n",
    "            continue \n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            j+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advertisement 폴더와 non_advertisement 폴더에서 각 파일 수의 1/4만큼 난수를 생성하고, 그 난수에 해당하는 ad 파일과 non 파일을 각각 valid_ad 폴더와 valid_non 폴더로 이동시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "n=1\n",
    "if(os.path.exists(ad_file_path) and num_of_files(ad_file_path)>0):\n",
    "    while num_of_files(ad_file_path)>0:\n",
    "        try:\n",
    "            os.rename(ad_file_path+'\\\\'+str(i)+'.jpg',train_ad+'\\\\'+str(n)+'.jpg')\n",
    "            i+=1\n",
    "            n+=1\n",
    "\n",
    "        except FileExistsError:\n",
    "            n=num_of_files(train_ad)+1\n",
    "            continue  \n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            i+=1\n",
    "            continue\n",
    "            \n",
    "j=1\n",
    "m=1\n",
    "if(os.path.exists(non_file_path) and num_of_files(non_file_path)>0):\n",
    "    while num_of_files(non_file_path)>0:\n",
    "        try:\n",
    "            os.rename(non_file_path+'\\\\'+str(j)+'.jpg',train_non+'\\\\'+str(m)+'.jpg')\n",
    "            j+=1\n",
    "            m+=1\n",
    "            \n",
    "        except FileExistsError:\n",
    "            m=num_of_files(train_non)+1\n",
    "            continue \n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            j+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advertisement 폴더와 non_advertisement 폴더에 남아 있는 ad , non 파일을 각각 train_ad 폴더와 train_non 폴더로 이동시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists(ad_file_path) and num_of_files(ad_file_path)==0):\n",
    "    if(num_of_files(dataset)>0):\n",
    "        os.rmdir(ad_file_path)\n",
    "        \n",
    "if(os.path.exists(non_file_path) and num_of_files(non_file_path)==0):\n",
    "    if(num_of_files(dataset)>0):\n",
    "        os.rmdir(non_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advertisement 폴더와 non_advertisement 폴더가 비었고, dataset 폴더에 파일이 존재한다면,\n",
    "advertisement 폴더와 non_advertisement 폴더를 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_SIZE=3\n",
    "NUM_FILTERS=25\n",
    "BATCH_SIZE=20\n",
    "MAXPOOL_SIZE=2\n",
    "STEPS_PER_EPOCH=500//BATCH_SIZE\n",
    "EPOCHS=30\n",
    "INPUT_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),\n",
    "                input_shape=(INPUT_SIZE,INPUT_SIZE,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(MAXPOOL_SIZE,MAXPOOL_SIZE)))\n",
    "\n",
    "model.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),\n",
    "                input_shape=(INPUT_SIZE,INPUT_SIZE,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(MAXPOOL_SIZE,MAXPOOL_SIZE)))\n",
    "\n",
    "model.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),\n",
    "                input_shape=(INPUT_SIZE,INPUT_SIZE,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(MAXPOOL_SIZE,MAXPOOL_SIZE)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 440 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n",
      "Found 156 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "im_generator=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "ITERATIONS=1\n",
    "images=[]\n",
    "\n",
    "train_generator=im_generator.flow_from_directory(train,target_size=(INPUT_SIZE,INPUT_SIZE),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True,seed=24)\n",
    "\n",
    "valid_generator=im_generator.flow_from_directory(valid,target_size=(INPUT_SIZE,INPUT_SIZE),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True,seed=24)\n",
    "\n",
    "test_generator=im_generator.flow_from_directory(test,target_size=(INPUT_SIZE,INPUT_SIZE),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True,seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ad': 0, 'non': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 0.7005 - accuracy: 0.5364WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 750 batches). You may need to use the repeat() function when building your dataset.\n",
      "25/25 [==============================] - 6s 190ms/step - loss: 0.6992 - accuracy: 0.5356 - val_loss: 0.6975 - val_accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(train_generator,steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                   validation_data=valid_generator,epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련 결과"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
