{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.models import Sequential \n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "import PIL\n",
    "import shutil\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_file_path='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\advertisement' # 일차적으로 수집한 광고 이미지\n",
    "ad_file_names=os.listdir(ad_file_path)\n",
    "non_file_path='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\non_advertisement' # 일차적으로 수집한 비광고 이미지\n",
    "non_file_names=os.listdir(non_file_path)\n",
    "\n",
    "# 파일명이 다 바꿔진 상태에선 실행시킬 필요 없는 코드\n",
    "i=1\n",
    "for name in ad_file_names:\n",
    "    try:\n",
    "        src=os.path.join(ad_file_path,name)\n",
    "        dst=str(i)+'.jpg'\n",
    "        dst=os.path.join(ad_file_path,dst)\n",
    "        os.rename(src,dst)\n",
    "        i+=1\n",
    "    except FileExistsError:\n",
    "        break\n",
    "\n",
    "j=1\n",
    "for name in non_file_names:\n",
    "    try:\n",
    "        src=os.path.join(non_file_path,name)\n",
    "        dst=str(j)+'.jpg'\n",
    "        dst=os.path.join(non_file_path,dst)\n",
    "        os.rename(src,dst)\n",
    "        j+=1\n",
    "    except FileExistsError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일의 확장자를 모두 '.jpg'로 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "for data in ad_file_names:\n",
    "    try:\n",
    "        file_name,file_extension=os.path.splitext(data)\n",
    "        correct_file_name=ad_file_path+'\\\\'+file_name+'.jpg'\n",
    "        if(file_extension!='.jpg'):\n",
    "            os.rename(ad_file_path+'\\\\'+data,correct_file_name)\n",
    "        i+=1\n",
    "    except FileExistsError:\n",
    "        break\n",
    "\n",
    "j=1\n",
    "for data in non_file_names:\n",
    "    try:\n",
    "        file_name,file_extension=os.path.splitext(data)\n",
    "        correct_file_name=non_file_path+'\\\\'+file_name+'.jpg'\n",
    "        if(file_extension!='.jpg'):\n",
    "            os.rename(non_file_path+'\\\\'+data,correct_file_name)\n",
    "        j+=1\n",
    "    except FileExistsError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더의 파일 개수를 구하는 함수\n",
    "def num_of_files(dir):\n",
    "    x=0\n",
    "    for pack in os.walk(dir):\n",
    "        for f in pack[2]:\n",
    "            x+=1\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "src_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\advertisement'\n",
    "src_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\non_advertisement'\n",
    "\n",
    "np.random.seed(13)\n",
    "test_ad_arr=np.random.randint(1,num_of_files(src_ad)+1,size=num_of_files(src_ad)//4)\n",
    "test_non_arr=np.random.randint(1,num_of_files(src_non)+1,size=num_of_files(src_non)//4)\n",
    "\n",
    "print(test_ad_arr)\n",
    "print(test_non_arr)\n",
    "\n",
    "test_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\test_ad'\n",
    "test_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\test_non'\n",
    "\n",
    "while(num_of_files(test_ad+'\\\\testing_ad')<len(test_ad_arr)):\n",
    "    i=1\n",
    "    for j in range(0,len(test_ad_arr),1):\n",
    "        filename=str(test_ad_arr[j])+'.jpg'\n",
    "        if os.path.exists(src_ad+'\\\\'+filename)==False:\n",
    "            continue\n",
    "\n",
    "        shutil.move(src_ad+'\\\\'+filename,test_ad+'\\\\testing_ad'+'\\\\'+str(i)+'.jpg')\n",
    "        i+=1\n",
    "\n",
    "while(num_of_files(test_non+'\\\\testing_non')<len(test_non_arr)):\n",
    "    k=1\n",
    "    for j in range(0,len(test_non_arr),1):    \n",
    "        filename=str(test_non_arr[j])+'.jpg'\n",
    "        if os.path.exists(src+filename)==False:\n",
    "            continue\n",
    "\n",
    "        shutil.move(src_non+'\\\\'+filename,test_non+'\\\\testing_non'+'\\\\'+str(k)+'.jpg')\n",
    "        k+=1\n",
    "\n",
    "if(os.path.isdir('C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\advertisement')==True):\n",
    "    os.rmdir('C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\advertisement')\n",
    "if(os.path.isdir('C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\non_advertisement')==True):\n",
    "    os.rmdir('C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\non_advertisement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_ad'\n",
    "os.makedirs(train_ad,exist_ok=True)\n",
    "train_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_non'\n",
    "os.makedirs(train_non,exist_ok=True)\n",
    "\n",
    "i=1\n",
    "for name in ad_file_names:\n",
    "    try:\n",
    "        file_name,file_extension=os.path.splitext(name)\n",
    "        if os.path.exists(ad_file_path+'\\\\'+name)==False:\n",
    "            i+=1\n",
    "            continue\n",
    "\n",
    "        shutil.move(ad_file_path+'\\\\'+name,train_ad+'\\\\'+name)\n",
    "        i+=1\n",
    "    except FileExistsError:\n",
    "        break\n",
    "    \n",
    "j=1\n",
    "for name in non_file_names:\n",
    "    try:\n",
    "        file_name,file_extension=os.path.splitext(name)\n",
    "        if os.path.exists(non_file_path+'\\\\'+name)==False:\n",
    "            continue\n",
    "\n",
    "        shutil.move(non_file_path+'\\\\'+name,train_non+'\\\\'+name)\n",
    "        j+=1\n",
    "    except FileExistsError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "ad_files=glob.glob(path_a+'\\\\*')\n",
    "\n",
    "\n",
    "for i, f in enumerate(ad_files):\n",
    "    try:\n",
    "        os.rename(f,os.path.join(path_a,'{:d}'.format(i+1)+'.jpg'))\n",
    "    except FileExistsError:\n",
    "        break\n",
    "    \n",
    "non_files=glob.glob(path_n+'\\\\*')\n",
    "\n",
    "for j, f in enumerate(non_files):\n",
    "    try:\n",
    "        os.rename(f,os.path.join(path_n,'{:d}'.format(j+1)+'.jpg'))\n",
    "    except FileExistsError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 지정된 파일을 찾을 수 없습니다: 'C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_ad\\\\19.jpg' -> 'C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_ad\\\\temp.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-07475055dc46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_ad_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_ad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_ad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'temp.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_ad\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\temp.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_ad\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\testing_ad\\\\'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_ad\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다: 'C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_ad\\\\19.jpg' -> 'C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_ad\\\\temp.jpg'"
     ]
    }
   ],
   "source": [
    "new_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_ad'\n",
    "new_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_non'\n",
    "\n",
    "new_ad_names=os.listdir(new_ad)\n",
    "new_non_names=os.listdir(new_non)\n",
    "\n",
    "i=1\n",
    "for name in new_ad_names:\n",
    "    try:\n",
    "        src=os.path.join(new_ad,name)\n",
    "        dst=str(i)+'.jpg'\n",
    "        dst=os.path.join(new_ad,dst)\n",
    "        os.rename(src,dst)\n",
    "        i+=1\n",
    "    except FileExistsError:\n",
    "        break\n",
    "\n",
    "j=1\n",
    "for name in new_non_names:\n",
    "    try:\n",
    "        src=os.path.join(new_non,name)\n",
    "        dst=str(j)+'.jpg'\n",
    "        dst=os.path.join(new_non,dst)\n",
    "        os.rename(src,dst)\n",
    "        j+=1\n",
    "    except FileExistsError:\n",
    "        break\n",
    "\n",
    "np.random.seed(13)\n",
    "new_ad_arr=np.random.randint(1,num_of_files(new_ad)+1,size=num_of_files(new_ad)//4)\n",
    "new_non_arr=np.random.randint(1,num_of_files(new_non)+1,size=num_of_files(new_non)//4)\n",
    "\n",
    "start_ad=num_of_files(test_ad+'\\\\testing_ad')+1\n",
    "start_non=num_of_files(test_non+'\\\\testing_non')+1\n",
    "\n",
    "# 새 데이터셋을 각 테스트 데이터셋에 넣음\n",
    "for k in range(0,len(new_ad_arr),1):\n",
    "    try:\n",
    "        data=str(new_ad_arr[k])+'.jpg'\n",
    "        os.rename(os.path.join(new_ad,data),os.path.join(new_ad,'temp.jpg'))\n",
    "        shutil.move(new_ad+'\\\\temp.jpg',test_ad+'\\\\testing_ad\\\\'+str(start_ad+k)+'.jpg')\n",
    "    except FileExistsError:\n",
    "        break\n",
    "#    os.rename(new_ad+'\\\\'+data,new_ad+'\\\\'+str(start_ad+k)+'.jpg')\n",
    "\n",
    "for k in range(0,len(new_non_arr),1):\n",
    "    try:\n",
    "        data=str(new_non_arr[k])+'.jpg'\n",
    "        os.rename(os.path.join(new_non,data),os.path.join(new_non,'temp.jpg'))\n",
    "        shutil.move(new_non+'\\\\temp.jpg',test_non+'\\\\testing_non\\\\'+str(start_non+k)+'.jpg')\n",
    "    except FileExistsError:\n",
    "        break\n",
    "\n",
    "training_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_ad\\\\training_ad'\n",
    "training_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_non\\\\training_non'\n",
    "\n",
    "start_ad=num_of_files(training_ad)+1\n",
    "start_non=num_of_files(training_non)+1\n",
    "\n",
    "# 새 데이터셋을 각 훈련 데이터셋에 넣음\n",
    "t=0\n",
    "for data in new_ad:\n",
    "    src=os.path.join(new_ad,data)\n",
    "    dst='temp'+'.jpg'\n",
    "    dst=os.path.join(new_ad,dst)\n",
    "    os.rename(src,dst)\n",
    "    shutil.move(new_ad+'\\\\temp.jpg',training_ad+str(start_ad+t)+'.jpg')\n",
    "    t+=1\n",
    "    \n",
    "t=0\n",
    "for data in new_non:\n",
    "    src=os.path.join(new_non,data)\n",
    "    dst='temp.jpg'\n",
    "    dst=os.path.join(new_non,dst)\n",
    "    os.rename(src,dst)\n",
    "    shutil.move(new_non+'\\\\temp.jpg',training_non+str(start_non+t)+'.jpg')\n",
    "    t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 images belonging to 2 classes.\n",
      "Found 34 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "generator=tf.keras.preprocessing.image.ImageDataGenerator( # rotation_range=30,\n",
    "    width_shift_range=0.2,height_shift_range=0.2,\n",
    "    zoom_range=0.2,rescale=1./255,\n",
    "    horizontal_flip=True,fill_mode='nearest')\n",
    "\n",
    "BATCH_SIZE=20\n",
    "ITERATIONS=3\n",
    "images=[]\n",
    "\n",
    "\n",
    "'''\n",
    "# 훈련 데이터(광고) 증강\n",
    "augmented_training_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_ad\\\\augmented_training_ad'\n",
    "\n",
    "train_ad_gen=generator.flow_from_directory(train_ad,target_size=(224,224),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=False,seed=21,save_to_dir=augmented_training_ad,\n",
    "                                    save_prefix='aug',save_format='jpg',\n",
    "                                    subset=None,interpolation='bilinear')\n",
    "\n",
    "for i in enumerate(range(ITERATIONS)):\n",
    "    img, label = train_ad_gen .next()\n",
    "    n_img = len(label)\n",
    "    \n",
    "    base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "    for idx in range(n_img - 1):\n",
    "        img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\n",
    "        base = np.hstack((base, img2))\n",
    "    images.append(base)\n",
    "    \n",
    "   \n",
    "# 훈련 데이터(비광고) 증강\n",
    "augmented_training_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_non\\\\augmented_training_non'\n",
    "\n",
    "train_non_gen=generator.flow_from_directory(train_non,target_size=(224,224),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=False,seed=21,save_to_dir=augmented_training_non,\n",
    "                                    save_prefix='aug',save_format='jpg',\n",
    "                                    subset=None,interpolation='bilinear')\n",
    "\n",
    "for i in enumerate(range(ITERATIONS)):\n",
    "    img, label = train_non_gen .next()\n",
    "    n_img = len(label)\n",
    "    \n",
    "    base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "    for idx in range(n_img - 1):\n",
    "        img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\n",
    "        base = np.hstack((base, img2))\n",
    "    images.append(base)\n",
    "'''    \n",
    "    \n",
    "# 테스트 데이터(광고) 증강\n",
    "augmented_testing_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\test_ad\\\\augmented_testing_ad'\n",
    "\n",
    "test_ad_gen=generator.flow_from_directory(test_ad,target_size=(224,224),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=False,seed=21,save_to_dir=augmented_testing_ad,\n",
    "                                    save_prefix='aug',save_format='jpg',\n",
    "                                    subset=None,interpolation='bilinear')\n",
    "\n",
    "for i in enumerate(range(ITERATIONS)):\n",
    "    img, label = test_ad_gen .next()\n",
    "    n_img = len(label)\n",
    "    \n",
    "    base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "    for idx in range(n_img - 1):\n",
    "        img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\n",
    "        base = np.hstack((base, img2))\n",
    "    images.append(base)\n",
    "    \n",
    "    \n",
    "# 테스트 데이터(비광고) 증강\n",
    "augmented_testing_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\test_non\\\\augmented_testing_non'\n",
    "\n",
    "test_non_gen=generator.flow_from_directory(test_non,target_size=(224,224),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=False,seed=21,save_to_dir=augmented_testing_non,\n",
    "                                    save_prefix='aug',save_format='jpg',\n",
    "                                    subset=None,interpolation='bilinear')\n",
    "\n",
    "for i in enumerate(range(ITERATIONS)):\n",
    "    img, label = test_non_gen .next()\n",
    "    n_img = len(label)\n",
    "    \n",
    "    base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "    for idx in range(n_img - 1):\n",
    "        img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\n",
    "        base = np.hstack((base, img2))\n",
    "    images.append(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터셋, 테스트 데이터셋 증강 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94 111 118  99  41  20  53  75  32  67  57  23  35   6  98  11  87  51\n",
      " 109  40  16 104  81  40  72  10  76  74   5  86 102]\n",
      "[104  93  82 114  67  54  36  58  56 105  61 102  70  33  50  69  55  93\n",
      "  82  13  84  50  46  85  18  84  70  26  52  92]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(19)\n",
    "valid_ad_arr=np.random.randint(1,num_of_files(training_ad)+1,size=num_of_files(training_ad)//4)\n",
    "valid_non_arr=np.random.randint(1,num_of_files(training_non)+1,size=num_of_files(training_non)//4)\n",
    "\n",
    "print(valid_ad_arr)\n",
    "print(valid_non_arr)\n",
    "\n",
    "valid_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\valid_ad'\n",
    "valid_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\valid_non'\n",
    "\n",
    "while(num_of_files(valid_ad)<len(valid_ad_arr)):\n",
    "    i=1\n",
    "    for j in range(0,len(valid_ad_arr),1):\n",
    "        filename=str(valid_ad_arr[j])+'.jpg'\n",
    "        if os.path.exists(training_ad+'\\\\'+filename)==False:\n",
    "            continue\n",
    "\n",
    "        shutil.move(training_ad+'\\\\'+filename,valid_ad+'\\\\'+str(i)+'.jpg')\n",
    "        i+=1\n",
    "\n",
    "while(num_of_files(valid_non)<len(valid_non_arr)):\n",
    "    i=1\n",
    "    for j in range(0,len(valid_non_arr),1):\n",
    "        filename=str(valid_non_arr[j])+'.jpg'\n",
    "        if os.path.exists(training_non+'\\\\'+filename)==False:\n",
    "            continue\n",
    "\n",
    "        shutil.move(training_non+'\\\\'+filename,valid_non+'\\\\'+str(i)+'.jpg')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터셋의 1/4를 검증 세트로 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_SIZE=3\n",
    "NUM_FILTERS=25\n",
    "BATCH_SIZE=20\n",
    "MAXPOOL_SIZE=2\n",
    "STEPS_PER_EPOCH=500//BATCH_SIZE\n",
    "EPOCHS=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),\n",
    "                input_shape=(32,32,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(MAXPOOL_SIZE,MAXPOOL_SIZE)))\n",
    "\n",
    "model.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),\n",
    "                input_shape=(32,32,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(MAXPOOL_SIZE,MAXPOOL_SIZE)))\n",
    "\n",
    "model.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),\n",
    "                input_shape=(32,32,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(MAXPOOL_SIZE,MAXPOOL_SIZE)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_train='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\input_for_train'\n",
    "os.makedirs(input_for_train,exist_ok=True)\n",
    "ad_for_train='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\input_for_train\\\\ad_for_train'\n",
    "os.makedirs(ad_for_train,exist_ok=True)\n",
    "non_for_train='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\input_for_train\\\\non_for_train'\n",
    "os.makedirs(non_for_train,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_ad\\\\training_ad'\n",
    "augmented_training_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_ad\\\\augmented_training_ad'\n",
    "new_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_ad'\n",
    "\n",
    "training_ad_dir=os.listdir(training_ad)\n",
    "augmented_training_ad_dir=os.listdir(augmented_training_ad)\n",
    "new_ad_dir=os.listdir(new_ad)\n",
    "\n",
    "i=1\n",
    "if(os.path.exists(training_ad) and num_of_files(training_ad)>0):\n",
    "    for file in training_ad_dir:\n",
    "        try:\n",
    "            os.rename(training_ad+'\\\\'+file,ad_for_train+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(ad_for_train)+1\n",
    "            continue\n",
    "            \n",
    "if(os.path.exists(augmented_training_ad) and num_of_files(augmented_training_ad)>0):\n",
    "    for file in augmented_training_ad_dir:\n",
    "        try:\n",
    "            os.rename(augmented_training_ad+'\\\\'+file,ad_for_train+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(ad_for_train)+1\n",
    "            continue\n",
    "            \n",
    "if(os.path.exists(new_ad) and num_of_files(new_ad)>0):\n",
    "    for file in new_ad_dir:\n",
    "        try:\n",
    "            os.rename(new_ad+'\\\\'+file,ad_for_train+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(ad_for_train)+1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "광고 데이터가 담긴 폴더들을 하나의 훈련 세트 폴더로 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_non\\\\training_non'\n",
    "augmented_training_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\train_non\\\\augmented_training_non'\n",
    "new_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\new_non'\n",
    "\n",
    "training_non_dir=os.listdir(training_non)\n",
    "augmented_training_non_dir=os.listdir(augmented_training_non)\n",
    "new_non_dir=os.listdir(new_non)\n",
    "\n",
    "i=1\n",
    "if(os.path.exists(training_non) and num_of_files(training_non)>0):\n",
    "    for file in training_non_dir:\n",
    "        try:\n",
    "            os.rename(training_non+'\\\\'+file,non_for_train+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(non_for_train)+1\n",
    "            continue\n",
    "            \n",
    "if(os.path.exists(augmented_training_non) and num_of_files(augmented_training_non)>0):\n",
    "    for file in augmented_training_non_dir:\n",
    "        try:\n",
    "            os.rename(augmented_training_non+'\\\\'+file,non_for_train+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(non_for_train)+1\n",
    "            continue\n",
    "            \n",
    "if(os.path.exists(new_non) and num_of_files(new_non)>0):\n",
    "    for file in new_non_dir:\n",
    "        try:\n",
    "            os.rename(new_non+'\\\\'+file,non_for_train+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(non_for_train)+1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비광고 데이터가 담긴 폴더들을 하나의 훈련 세트 폴더로 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_valid='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\input_for_valid'\n",
    "os.makedirs(input_for_valid,exist_ok=True)\n",
    "ad_for_valid='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\input_for_valid\\\\ad_for_valid'\n",
    "os.makedirs(ad_for_valid,exist_ok=True)\n",
    "non_for_valid='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\input_for_valid\\\\non_for_valid'\n",
    "os.makedirs(non_for_valid,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\valid_ad'\n",
    "valid_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\valid_non'\n",
    "\n",
    "valid_ad_dir=os.listdir(valid_ad)\n",
    "valid_non_dir=os.listdir(valid_non)\n",
    "\n",
    "i=1\n",
    "if(os.path.exists(valid_ad) and num_of_files(valid_ad)>0):\n",
    "    for file in valid_ad_dir:\n",
    "        try:\n",
    "            os.rename(valid_ad+'\\\\'+file,ad_for_valid+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(ad_for_valid)+1\n",
    "            continue\n",
    "\n",
    "i=1\n",
    "if(os.path.exists(valid_non) and num_of_files(valid_non)>0):\n",
    "    for file in valid_non_dir:\n",
    "        try:\n",
    "            os.rename(valid_non+'\\\\'+file,non_for_valid+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(non_for_valid)+1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터(광고,비광고)가 담긴 폴더들을 하나의 검증 세트 폴더로 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_test='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\input_for_test'\n",
    "os.makedirs(input_for_test,exist_ok=True)\n",
    "ad_for_test='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\input_for_test\\\\ad_for_test'\n",
    "os.makedirs(ad_for_test,exist_ok=True)\n",
    "non_for_test='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\input_for_test\\\\non_for_test'\n",
    "os.makedirs(non_for_test,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ad='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\test_ad\\\\testing_ad'\n",
    "testing_non='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\test_non\\\\testing_non'\n",
    "\n",
    "testing_ad_dir=os.listdir(testing_ad)\n",
    "testing_non_dir=os.listdir(testing_non)\n",
    "\n",
    "i=1\n",
    "if(os.path.exists(testing_ad) and num_of_files(testing_ad)>0):\n",
    "    for file in testing_ad_dir:\n",
    "        try:\n",
    "            os.rename(testing_ad+'\\\\'+file,ad_for_test+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(ad_for_test)+1\n",
    "            continue\n",
    "            \n",
    "i=1\n",
    "if(os.path.exists(testing_non) and num_of_files(testing_non)>0):\n",
    "    for file in testing_non_dir:\n",
    "        try:\n",
    "            os.rename(testing_non+'\\\\'+file,non_for_test+'\\\\'+str(i)+'.jpg')\n",
    "            i+=1\n",
    "        except FileExistsError:\n",
    "            i=num_of_files(non_for_test)+1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터(광고,비광고)가 담긴 폴더들을 하나의 테스트 세트 폴더로 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset'\n",
    "# os.makedirs(dataset,exist_ok=True)\n",
    "training_set='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\training_set'\n",
    "# os.makedirs(training_set,exist_ok=True)\n",
    "validation_set='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\validation_set'\n",
    "# os.makedirs(validation_set,exist_ok=True)\n",
    "testing_set='C:\\\\Users\\\\USER\\\\Desktop\\\\united_input\\\\dataset\\\\testing_set'\n",
    "# os.makedirs(testing_set,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset 폴더를 만들고 위의 테스트 세트, 훈련 세트, 검증 세트를 하위 폴더에 복사하였음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 하위 폴더들의 이름을 ad, non 으로 이진분류하여 수정했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 389 images belonging to 2 classes.\n",
      "Found 58 images belonging to 2 classes.\n",
      "Found 132 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "im_generator=tf.keras.preprocessing.image.ImageDataGenerator( \n",
    "    zoom_range=0.2,rescale=1./255)\n",
    "\n",
    "ITERATIONS=1\n",
    "images=[]\n",
    "\n",
    "train_generator=im_generator.flow_from_directory(training_set,target_size=(32,32),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True,seed=24)\n",
    "\n",
    "valid_generator=im_generator.flow_from_directory(validation_set,target_size=(32,32),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True,seed=24)\n",
    "\n",
    "test_generator=im_generator.flow_from_directory(testing_set,target_size=(32,32),\n",
    "                                    class_mode='binary',batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True,seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ad': 0, 'non': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 0.7049 - accuracy: 0.4507WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need to use the repeat() function when building your dataset.\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.7038 - accuracy: 0.4546 - val_loss: 0.6907 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(train_generator,steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                   validation_data=valid_generator,epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련 결과"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
